{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmrcua0fGo+jWtEuWRgTjN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MdShakil-Hossain/366-Final-Lab/blob/main/CSE_366_Final_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision matplotlib grad-cam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQCr2LfG-iq-",
        "outputId": "45ec557e-926e-44e4-9776-b7f0ab8f3168"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: grad-cam in /usr/local/lib/python3.11/dist-packages (1.5.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: ttach in /usr/local/lib/python3.11/dist-packages (from grad-cam) (0.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from grad-cam) (4.67.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from grad-cam) (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from grad-cam) (1.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->grad-cam) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->grad-cam) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->grad-cam) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Mounting\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM7c8Kov_LM9",
        "outputId": "bd1e8eb8-e862-44e6-fc20-beb8a213bdda"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Path_to_dataset\n",
        "dataset_path = '/content/drive/MyDrive/CSE 366 Lab/caltech-101'"
      ],
      "metadata": {
        "id": "sIG5s4U4Ahg_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "from torchvision import datasets, transforms, models\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image"
      ],
      "metadata": {
        "id": "N6UYJzI0O-2Q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
        "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "qkl9I4hgPCSw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset\n",
        "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
        "\n",
        "#Number of classes\n",
        "num_classes = len(dataset.classes)\n",
        "print(f\"Number of classes in the dataset: {num_classes}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6cpXcI3PICo",
        "outputId": "7d925a42-c9a5-45bc-e7c9-bfbb5d65313f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes in the dataset: 102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Split dataset into training, validation and testing sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])"
      ],
      "metadata": {
        "id": "6x49C4deQwbx"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DataLoaders\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=32)\n",
        "test_loader = DataLoader(test_data, batch_size=32)"
      ],
      "metadata": {
        "id": "TS_mji5CQ1kP"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using ResNet50 as the pre-trained model\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.fc = nn.Linear(2048, num_classes)"
      ],
      "metadata": {
        "id": "VIHivQcGQ454"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "vr126mIWQ8s4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvdHjhyUQ_k3",
        "outputId": "d2fa5913-7d12-45d3-cad7-8b8f105933da"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 3.5704\n",
            "Epoch 2, Loss: 2.7344\n",
            "Epoch 3, Loss: 2.3662\n",
            "Epoch 4, Loss: 2.0330\n",
            "Epoch 5, Loss: 1.7701\n",
            "Epoch 6, Loss: 1.5812\n",
            "Epoch 7, Loss: 1.4904\n",
            "Epoch 8, Loss: 1.3383\n",
            "Epoch 9, Loss: 1.2293\n",
            "Epoch 10, Loss: 1.1270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "val_accuracy = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        val_accuracy += (preds == labels).sum().item()\n",
        "val_accuracy /= len(val_data)\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5X_SzUMEq8bt",
        "outputId": "5ab4dee3-26be-4aa4-c84a-678228c3a3ce"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 1.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = 0\n",
        "y_pred, y_true = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        test_accuracy += (preds == labels).sum().item()\n",
        "        y_pred.extend(preds.cpu().numpy())\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "\n",
        "test_accuracy /= len(test_data)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1OeNiNmrHD7",
        "outputId": "d840d7a5-ffe5-49c3-cdb2-49af483c0b77"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "report = classification_report(y_true, y_pred, target_names=dataset.classes)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNNcdZQLrIYU",
        "outputId": "ad451501-2bf5-48b2-ff22-7f8e59e8b6cb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[1 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "Classification Report:\n",
            "                    precision    recall  f1-score   support\n",
            "\n",
            "BACKGROUND_Google       1.00      0.02      0.05        41\n",
            "            Faces       0.00      0.00      0.00        34\n",
            "       Faces_easy       0.00      0.00      0.00        38\n",
            "         Leopards       0.00      0.00      0.00        24\n",
            "       Motorbikes       0.00      0.00      0.00        78\n",
            "        accordion       0.00      0.00      0.00         7\n",
            "        airplanes       0.00      0.00      0.00        83\n",
            "           anchor       0.00      0.00      0.00         6\n",
            "              ant       0.00      0.00      0.00         5\n",
            "           barrel       0.00      0.00      0.00         6\n",
            "             bass       0.00      0.00      0.00         8\n",
            "           beaver       0.00      0.00      0.00         5\n",
            "        binocular       0.00      0.00      0.00         5\n",
            "           bonsai       0.00      0.00      0.00        11\n",
            "            brain       0.00      0.00      0.00        11\n",
            "     brontosaurus       0.00      0.00      0.00         6\n",
            "           buddha       0.00      0.00      0.00         6\n",
            "        butterfly       0.00      0.00      0.00         6\n",
            "           camera       0.01      0.17      0.01         6\n",
            "           cannon       0.00      0.00      0.00         3\n",
            "         car_side       0.00      0.00      0.00        17\n",
            "      ceiling_fan       0.00      0.00      0.00         3\n",
            "        cellphone       0.00      0.00      0.00         6\n",
            "            chair       0.00      0.00      0.00         4\n",
            "       chandelier       0.00      0.00      0.00         9\n",
            "      cougar_body       0.00      0.00      0.00         2\n",
            "      cougar_face       0.00      0.00      0.00         7\n",
            "             crab       0.00      0.00      0.00        12\n",
            "         crayfish       0.00      0.00      0.00        11\n",
            "        crocodile       0.00      0.00      0.00         3\n",
            "   crocodile_head       0.00      0.00      0.00         2\n",
            "              cup       0.00      0.00      0.00         7\n",
            "        dalmatian       0.00      0.00      0.00         8\n",
            "      dollar_bill       0.00      0.00      0.00         4\n",
            "          dolphin       0.00      0.00      0.00         8\n",
            "        dragonfly       0.00      0.00      0.00         5\n",
            "  electric_guitar       0.00      0.00      0.00         7\n",
            "         elephant       0.00      0.00      0.00         7\n",
            "              emu       0.00      0.00      0.00         3\n",
            "        euphonium       0.08      0.20      0.12         5\n",
            "             ewer       0.00      0.00      0.00         8\n",
            "            ferry       0.00      0.00      0.00         6\n",
            "         flamingo       0.00      0.00      0.00         7\n",
            "    flamingo_head       0.00      0.00      0.00         4\n",
            "         garfield       0.00      0.00      0.00         6\n",
            "          gerenuk       0.00      0.00      0.00         2\n",
            "       gramophone       0.00      0.00      0.00         4\n",
            "      grand_piano       0.00      0.00      0.00         7\n",
            "        hawksbill       0.00      0.00      0.00         7\n",
            "        headphone       0.00      0.00      0.00         5\n",
            "         hedgehog       0.00      0.00      0.00         4\n",
            "       helicopter       0.00      0.00      0.00         6\n",
            "             ibis       0.00      0.00      0.00         9\n",
            "     inline_skate       0.00      0.00      0.00         4\n",
            "      joshua_tree       0.00      0.00      0.00         5\n",
            "         kangaroo       0.00      0.00      0.00         8\n",
            "            ketch       0.02      0.12      0.04         8\n",
            "             lamp       0.00      0.00      0.00        10\n",
            "           laptop       0.00      0.00      0.00         7\n",
            "            llama       0.00      0.00      0.00         9\n",
            "          lobster       0.00      0.00      0.00         6\n",
            "            lotus       0.00      0.00      0.00         6\n",
            "         mandolin       0.00      0.00      0.00         6\n",
            "           mayfly       0.00      0.00      0.00         6\n",
            "          menorah       0.00      0.00      0.00         8\n",
            "        metronome       0.00      0.00      0.00         6\n",
            "          minaret       0.00      0.00      0.00        10\n",
            "         nautilus       0.00      0.00      0.00         4\n",
            "          octopus       0.00      0.00      0.00         2\n",
            "            okapi       0.00      0.00      0.00         1\n",
            "           pagoda       0.00      0.00      0.00         5\n",
            "            panda       0.00      0.00      0.00         3\n",
            "           pigeon       0.00      0.00      0.00         2\n",
            "            pizza       0.00      0.00      0.00         7\n",
            "         platypus       0.00      0.00      0.00         5\n",
            "          pyramid       0.00      0.00      0.00         8\n",
            "         revolver       0.00      0.00      0.00        15\n",
            "            rhino       0.33      0.25      0.29         4\n",
            "          rooster       0.00      0.00      0.00         5\n",
            "        saxophone       0.00      0.00      0.00         6\n",
            "         schooner       0.00      0.00      0.00         5\n",
            "         scissors       0.00      0.00      0.00         6\n",
            "         scorpion       0.00      0.00      0.00         7\n",
            "        sea_horse       0.00      0.00      0.00         6\n",
            "           snoopy       0.00      0.00      0.00         2\n",
            "      soccer_ball       0.00      0.00      0.00         6\n",
            "          stapler       0.00      0.00      0.00         2\n",
            "         starfish       0.00      0.00      0.00         8\n",
            "      stegosaurus       0.00      0.00      0.00         9\n",
            "        stop_sign       0.00      0.00      0.00         8\n",
            "       strawberry       0.00      0.00      0.00         4\n",
            "        sunflower       0.00      0.00      0.00         9\n",
            "             tick       0.00      0.00      0.00         7\n",
            "        trilobite       0.00      0.00      0.00        13\n",
            "         umbrella       0.00      0.00      0.00         7\n",
            "            watch       0.00      0.00      0.00        26\n",
            "      water_lilly       0.00      0.00      0.00         3\n",
            "       wheelchair       0.00      0.00      0.00         5\n",
            "         wild_cat       0.00      0.00      0.00         2\n",
            "    windsor_chair       0.00      0.00      0.00         8\n",
            "           wrench       0.00      0.00      0.00         7\n",
            "         yin_yang       0.00      0.00      0.00         5\n",
            "\n",
            "         accuracy                           0.01       915\n",
            "        macro avg       0.01      0.01      0.00       915\n",
            "     weighted avg       0.05      0.01      0.00       915\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ResNet50 architecture\n",
        "target_layer = model.layer4[-1]\n",
        "cam = GradCAM(model=model, target_layer=target_layer)\n",
        "\n",
        "#Display Grad-CAM for the first test image\n",
        "for images, labels in test_loader:\n",
        "    grayscale_cam = cam(input_tensor=images, target_category=labels[0])\n",
        "    cam_image = show_cam_on_image(images[0].permute(1, 2, 0).cpu().numpy(), grayscale_cam)\n",
        "    plt.imshow(cam_image)\n",
        "    plt.show()\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "mMDCk-wGrMFM",
        "outputId": "7d904756-02e7-4729-91c4-ee44a354d77b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function BaseCAM.__del__ at 0x7d60026e9440>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pytorch_grad_cam/base_cam.py\", line 189, in __del__\n",
            "    self.activations_and_grads.release()\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'GradCAM' object has no attribute 'activations_and_grads'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "GradCAM.__init__() got an unexpected keyword argument 'target_layer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-af46e2885801>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#ResNet50 architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtarget_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradCAM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#Display Grad-CAM for the first test image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: GradCAM.__init__() got an unexpected keyword argument 'target_layer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"caltech101_resnet50.pth\")"
      ],
      "metadata": {
        "id": "c8kZOj6urPh8"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}